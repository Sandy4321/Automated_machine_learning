{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Documentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) http://auto-ml.readthedocs.io/en/latest/api_docs_for_geeks.html  \n",
    "2) https://github.com/ClimbsRocks/auto_ml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_excel(\"bank.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['target'] = df['y'].apply(lambda x: 1 if x == 'yes' else 0)\n",
    "df.drop('y',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>balance</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>duration</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30</td>\n",
       "      <td>unemployed</td>\n",
       "      <td>married</td>\n",
       "      <td>primary</td>\n",
       "      <td>no</td>\n",
       "      <td>1787</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>19</td>\n",
       "      <td>oct</td>\n",
       "      <td>79</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>33</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>4789</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>cellular</td>\n",
       "      <td>11</td>\n",
       "      <td>may</td>\n",
       "      <td>220</td>\n",
       "      <td>1</td>\n",
       "      <td>339</td>\n",
       "      <td>4</td>\n",
       "      <td>failure</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>35</td>\n",
       "      <td>management</td>\n",
       "      <td>single</td>\n",
       "      <td>tertiary</td>\n",
       "      <td>no</td>\n",
       "      <td>1350</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>16</td>\n",
       "      <td>apr</td>\n",
       "      <td>185</td>\n",
       "      <td>1</td>\n",
       "      <td>330</td>\n",
       "      <td>1</td>\n",
       "      <td>failure</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30</td>\n",
       "      <td>management</td>\n",
       "      <td>married</td>\n",
       "      <td>tertiary</td>\n",
       "      <td>no</td>\n",
       "      <td>1476</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>unknown</td>\n",
       "      <td>3</td>\n",
       "      <td>jun</td>\n",
       "      <td>199</td>\n",
       "      <td>4</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>59</td>\n",
       "      <td>blue-collar</td>\n",
       "      <td>married</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>226</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age          job  marital  education default  balance housing loan  \\\n",
       "0   30   unemployed  married    primary      no     1787      no   no   \n",
       "1   33     services  married  secondary      no     4789     yes  yes   \n",
       "2   35   management   single   tertiary      no     1350     yes   no   \n",
       "3   30   management  married   tertiary      no     1476     yes  yes   \n",
       "4   59  blue-collar  married  secondary      no        0     yes   no   \n",
       "\n",
       "    contact  day month  duration  campaign  pdays  previous poutcome  target  \n",
       "0  cellular   19   oct        79         1     -1         0  unknown       0  \n",
       "1  cellular   11   may       220         1    339         4  failure       0  \n",
       "2  cellular   16   apr       185         1    330         1  failure       0  \n",
       "3   unknown    3   jun       199         4     -1         0  unknown       0  \n",
       "4   unknown    5   may       226         1     -1         0  unknown       0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target       0.0\n",
       "loan         0.0\n",
       "job          0.0\n",
       "marital      0.0\n",
       "education    0.0\n",
       "default      0.0\n",
       "balance      0.0\n",
       "housing      0.0\n",
       "contact      0.0\n",
       "poutcome     0.0\n",
       "day          0.0\n",
       "month        0.0\n",
       "duration     0.0\n",
       "campaign     0.0\n",
       "pdays        0.0\n",
       "previous     0.0\n",
       "age          0.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().mean().sort_values(ascending=False)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['job', 'marital', 'education', 'default', 'housing', 'loan', 'contact',\n",
       "       'month', 'poutcome'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.select_dtypes(include=['object']).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Data transformation\n",
    "# Convert categorical values to numeric using label encoder\n",
    "from sklearn import preprocessing\n",
    "from collections import defaultdict\n",
    "d = defaultdict(preprocessing.LabelEncoder)\n",
    "\n",
    "# Encoding the categorical variable\n",
    "fit = df.select_dtypes(include=['object']).fillna('NA').apply(lambda x: d[x.name].fit_transform(x))\n",
    "\n",
    "#Convert the categorical columns based on encoding\n",
    "for i in list(d.keys()):\n",
    "    df[i] = d[i].transform(df[i].fillna('NA'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mbagav200/anaconda/lib/python3.5/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "train, test = train_test_split(df, test_size = 0.4)\n",
    "train = train.reset_index(drop=True)\n",
    "test = test.reset_index(drop=True)\n",
    "\n",
    "features_train = train[train.columns.difference(['target'])]\n",
    "label_train = train['target']\n",
    "features_test = test[test.columns.difference(['target'])]\n",
    "label_test = test['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from auto_ml import Predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "col_desc_dictionary = {'target': 'output',\n",
    "                       'job': 'categorical', \n",
    "                       'marital': 'categorical', \n",
    "                       'education': 'categorical', \n",
    "                       'default': 'categorical', \n",
    "                       'housing': 'categorical', \n",
    "                       'loan': 'categorical', \n",
    "                       'contact': 'categorical',\n",
    "                       'month': 'categorical', \n",
    "                       'poutcome': 'categorical'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ml_predictor = Predictor(type_of_estimator='classifier', column_descriptions=col_desc_dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to auto_ml! We're about to go through and make sense of your data using machine learning, and give you a production-ready pipeline to get predictions with.\n",
      "\n",
      "If you have any issues, or new feature ideas, let us know at http://auto.ml\n",
      "You are running on version 2.9.10\n",
      "Now using the model training_params that you passed in:\n",
      "{}\n",
      "After overwriting our defaults with your values, here are the final params that will be used to initialize the model:\n",
      "{'learning_rate': 0.1, 'presort': False, 'warm_start': True}\n",
      "Running basic data cleaning\n",
      "Fitting DataFrameVectorizer\n",
      "Now using the model training_params that you passed in:\n",
      "{}\n",
      "After overwriting our defaults with your values, here are the final params that will be used to initialize the model:\n",
      "{'learning_rate': 0.1, 'presort': False, 'warm_start': True}\n",
      "\n",
      "\n",
      "********************************************************************************************\n",
      "About to fit the pipeline for the model GradientBoostingClassifier to predict target\n",
      "Started at:\n",
      "2018-08-09 17:18:50\n",
      "[1] random_holdout_set_from_training_data's score is: -0.114\n",
      "[2] random_holdout_set_from_training_data's score is: -0.109\n",
      "[3] random_holdout_set_from_training_data's score is: -0.106\n",
      "[4] random_holdout_set_from_training_data's score is: -0.103\n",
      "[5] random_holdout_set_from_training_data's score is: -0.101\n",
      "[6] random_holdout_set_from_training_data's score is: -0.1\n",
      "[7] random_holdout_set_from_training_data's score is: -0.098\n",
      "[8] random_holdout_set_from_training_data's score is: -0.097\n",
      "[9] random_holdout_set_from_training_data's score is: -0.095\n",
      "[10] random_holdout_set_from_training_data's score is: -0.093\n",
      "[11] random_holdout_set_from_training_data's score is: -0.093\n",
      "[12] random_holdout_set_from_training_data's score is: -0.092\n",
      "[13] random_holdout_set_from_training_data's score is: -0.091\n",
      "[14] random_holdout_set_from_training_data's score is: -0.089\n",
      "[15] random_holdout_set_from_training_data's score is: -0.089\n",
      "[16] random_holdout_set_from_training_data's score is: -0.089\n",
      "[17] random_holdout_set_from_training_data's score is: -0.088\n",
      "[18] random_holdout_set_from_training_data's score is: -0.087\n",
      "[19] random_holdout_set_from_training_data's score is: -0.087\n",
      "[20] random_holdout_set_from_training_data's score is: -0.087\n",
      "[21] random_holdout_set_from_training_data's score is: -0.087\n",
      "[22] random_holdout_set_from_training_data's score is: -0.086\n",
      "[23] random_holdout_set_from_training_data's score is: -0.086\n",
      "[24] random_holdout_set_from_training_data's score is: -0.086\n",
      "[25] random_holdout_set_from_training_data's score is: -0.086\n",
      "[26] random_holdout_set_from_training_data's score is: -0.086\n",
      "[27] random_holdout_set_from_training_data's score is: -0.086\n",
      "[28] random_holdout_set_from_training_data's score is: -0.086\n",
      "[29] random_holdout_set_from_training_data's score is: -0.086\n",
      "[30] random_holdout_set_from_training_data's score is: -0.086\n",
      "[31] random_holdout_set_from_training_data's score is: -0.086\n",
      "[32] random_holdout_set_from_training_data's score is: -0.086\n",
      "[33] random_holdout_set_from_training_data's score is: -0.086\n",
      "[34] random_holdout_set_from_training_data's score is: -0.086\n",
      "[35] random_holdout_set_from_training_data's score is: -0.086\n",
      "[36] random_holdout_set_from_training_data's score is: -0.087\n",
      "[37] random_holdout_set_from_training_data's score is: -0.086\n",
      "[38] random_holdout_set_from_training_data's score is: -0.086\n",
      "[39] random_holdout_set_from_training_data's score is: -0.086\n",
      "[40] random_holdout_set_from_training_data's score is: -0.086\n",
      "[41] random_holdout_set_from_training_data's score is: -0.086\n",
      "[42] random_holdout_set_from_training_data's score is: -0.085\n",
      "[43] random_holdout_set_from_training_data's score is: -0.086\n",
      "[44] random_holdout_set_from_training_data's score is: -0.086\n",
      "[45] random_holdout_set_from_training_data's score is: -0.085\n",
      "[46] random_holdout_set_from_training_data's score is: -0.085\n",
      "[47] random_holdout_set_from_training_data's score is: -0.086\n",
      "[48] random_holdout_set_from_training_data's score is: -0.086\n",
      "[49] random_holdout_set_from_training_data's score is: -0.086\n",
      "[50] random_holdout_set_from_training_data's score is: -0.086\n",
      "[52] random_holdout_set_from_training_data's score is: -0.086\n",
      "[54] random_holdout_set_from_training_data's score is: -0.086\n",
      "[56] random_holdout_set_from_training_data's score is: -0.085\n",
      "[58] random_holdout_set_from_training_data's score is: -0.085\n",
      "[60] random_holdout_set_from_training_data's score is: -0.086\n",
      "[62] random_holdout_set_from_training_data's score is: -0.086\n",
      "[64] random_holdout_set_from_training_data's score is: -0.086\n",
      "[66] random_holdout_set_from_training_data's score is: -0.086\n",
      "[68] random_holdout_set_from_training_data's score is: -0.086\n",
      "[70] random_holdout_set_from_training_data's score is: -0.086\n",
      "[72] random_holdout_set_from_training_data's score is: -0.086\n",
      "[74] random_holdout_set_from_training_data's score is: -0.086\n",
      "The number of estimators that were the best for this training dataset: 42\n",
      "The best score on the holdout set: -0.08521048194363635\n",
      "Finished training the pipeline!\n",
      "Total training time:\n",
      "0:00:01\n",
      "\n",
      "\n",
      "Here are the results from our GradientBoostingClassifier\n",
      "predicting target\n",
      "Calculating feature responses, for advanced analytics.\n",
      "The printed list will only contain at most the top 100 features.\n",
      "+---------+----------------+--------------+-----------+-------------------+-------------------+-----------+-----------+-----------+-----------+\n",
      "|         | Feature Name   |   Importance |     Delta |   FR_Decrementing |   FR_Incrementing |   FRD_abs |   FRI_abs |   FRD_MAD |   FRI_MAD |\n",
      "|---------+----------------+--------------+-----------+-------------------+-------------------+-----------+-----------+-----------+-----------|\n",
      "| 50.0000 | poutcome=3     |       0.0000 |  nan      |          nan      |          nan      |  nan      |  nan      |  nan      |  nan      |\n",
      "| 44.0000 | month=9        |       0.0000 |  nan      |          nan      |          nan      |  nan      |  nan      |  nan      |  nan      |\n",
      "| 40.0000 | month=5        |       0.0000 |  nan      |          nan      |          nan      |  nan      |  nan      |  nan      |  nan      |\n",
      "| 39.0000 | month=4        |       0.0000 |  nan      |          nan      |          nan      |  nan      |  nan      |  nan      |  nan      |\n",
      "| 33.0000 | contact=1      |       0.0000 |  nan      |          nan      |          nan      |  nan      |  nan      |  nan      |  nan      |\n",
      "| 22.0000 | education=0    |       0.0000 |  nan      |          nan      |          nan      |  nan      |  nan      |  nan      |  nan      |\n",
      "|  7.0000 | job=0          |       0.0000 |  nan      |          nan      |          nan      |  nan      |  nan      |  nan      |  nan      |\n",
      "|  9.0000 | job=2          |       0.0000 |  nan      |          nan      |          nan      |  nan      |  nan      |  nan      |  nan      |\n",
      "| 10.0000 | job=3          |       0.0000 |  nan      |          nan      |          nan      |  nan      |  nan      |  nan      |  nan      |\n",
      "| 11.0000 | job=4          |       0.0000 |  nan      |          nan      |          nan      |  nan      |  nan      |  nan      |  nan      |\n",
      "| 19.0000 | marital=0      |       0.0000 |  nan      |          nan      |          nan      |  nan      |  nan      |  nan      |  nan      |\n",
      "| 18.0000 | job=11         |       0.0000 |  nan      |          nan      |          nan      |  nan      |  nan      |  nan      |  nan      |\n",
      "| 14.0000 | job=7          |       0.0000 |  nan      |          nan      |          nan      |  nan      |  nan      |  nan      |  nan      |\n",
      "| 17.0000 | job=10         |       0.0000 |  nan      |          nan      |          nan      |  nan      |  nan      |  nan      |  nan      |\n",
      "| 20.0000 | marital=1      |       0.0000 |  nan      |          nan      |          nan      |  nan      |  nan      |  nan      |  nan      |\n",
      "| 48.0000 | poutcome=1     |       0.0002 |  nan      |          nan      |          nan      |  nan      |  nan      |  nan      |  nan      |\n",
      "| 25.0000 | education=3    |       0.0004 |  nan      |          nan      |          nan      |  nan      |  nan      |  nan      |  nan      |\n",
      "| 24.0000 | education=2    |       0.0021 |  nan      |          nan      |          nan      |  nan      |  nan      |  nan      |  nan      |\n",
      "| 28.0000 | housing=0      |       0.0023 |  nan      |          nan      |          nan      |  nan      |  nan      |  nan      |  nan      |\n",
      "|  4.0000 | campaign       |       0.0029 |    1.5170 |            0.0001 |           -0.0003 |    0.0001 |    0.0003 |    0.0000 |    0.0000 |\n",
      "| 43.0000 | month=8        |       0.0030 |  nan      |          nan      |          nan      |  nan      |  nan      |  nan      |  nan      |\n",
      "|  8.0000 | job=1          |       0.0036 |  nan      |          nan      |          nan      |  nan      |  nan      |  nan      |  nan      |\n",
      "| 37.0000 | month=2        |       0.0040 |  nan      |          nan      |          nan      |  nan      |  nan      |  nan      |  nan      |\n",
      "| 26.0000 | default=0      |       0.0042 |  nan      |          nan      |          nan      |  nan      |  nan      |  nan      |  nan      |\n",
      "| 35.0000 | month=0        |       0.0047 |  nan      |          nan      |          nan      |  nan      |  nan      |  nan      |  nan      |\n",
      "| 38.0000 | month=3        |       0.0056 |  nan      |          nan      |          nan      |  nan      |  nan      |  nan      |  nan      |\n",
      "| 21.0000 | marital=2      |       0.0061 |  nan      |          nan      |          nan      |  nan      |  nan      |  nan      |  nan      |\n",
      "| 15.0000 | job=8          |       0.0067 |  nan      |          nan      |          nan      |  nan      |  nan      |  nan      |  nan      |\n",
      "| 47.0000 | poutcome=0     |       0.0068 |  nan      |          nan      |          nan      |  nan      |  nan      |  nan      |  nan      |\n",
      "| 27.0000 | default=1      |       0.0071 |  nan      |          nan      |          nan      |  nan      |  nan      |  nan      |  nan      |\n",
      "| 30.0000 | loan=0         |       0.0075 |  nan      |          nan      |          nan      |  nan      |  nan      |  nan      |  nan      |\n",
      "| 16.0000 | job=9          |       0.0089 |  nan      |          nan      |          nan      |  nan      |  nan      |  nan      |  nan      |\n",
      "| 12.0000 | job=5          |       0.0091 |  nan      |          nan      |          nan      |  nan      |  nan      |  nan      |  nan      |\n",
      "| 13.0000 | job=6          |       0.0091 |  nan      |          nan      |          nan      |  nan      |  nan      |  nan      |  nan      |\n",
      "| 29.0000 | housing=1      |       0.0101 |  nan      |          nan      |          nan      |  nan      |  nan      |  nan      |  nan      |\n",
      "| 31.0000 | loan=1         |       0.0123 |  nan      |          nan      |          nan      |  nan      |  nan      |  nan      |  nan      |\n",
      "| 46.0000 | month=11       |       0.0130 |  nan      |          nan      |          nan      |  nan      |  nan      |  nan      |  nan      |\n",
      "| 32.0000 | contact=0      |       0.0155 |  nan      |          nan      |          nan      |  nan      |  nan      |  nan      |  nan      |\n",
      "|  6.0000 | previous       |       0.0157 |    0.8827 |           -0.0009 |            0.0014 |    0.0009 |    0.0014 |    0.0000 |    0.0000 |\n",
      "| 36.0000 | month=1        |       0.0167 |  nan      |          nan      |          nan      |  nan      |  nan      |  nan      |  nan      |\n",
      "| 23.0000 | education=1    |       0.0171 |  nan      |          nan      |          nan      |  nan      |  nan      |  nan      |  nan      |\n",
      "| 34.0000 | contact=2      |       0.0257 |  nan      |          nan      |          nan      |  nan      |  nan      |  nan      |  nan      |\n",
      "|  1.0000 | balance        |       0.0339 | 1507.7351 |            0.0003 |            0.0018 |    0.0030 |    0.0058 |    0.0000 |    0.0000 |\n",
      "| 41.0000 | month=6        |       0.0399 |  nan      |          nan      |          nan      |  nan      |  nan      |  nan      |  nan      |\n",
      "|  5.0000 | pdays          |       0.0483 |   49.6598 |           -0.0009 |            0.0015 |    0.0012 |    0.0020 |    0.0000 |    0.0000 |\n",
      "| 45.0000 | month=10       |       0.0555 |  nan      |          nan      |          nan      |  nan      |  nan      |  nan      |  nan      |\n",
      "| 42.0000 | month=7        |       0.0604 |  nan      |          nan      |          nan      |  nan      |  nan      |  nan      |  nan      |\n",
      "|  2.0000 | day            |       0.0647 |    4.1187 |            0.0125 |            0.0005 |    0.0144 |    0.0029 |    0.0000 |    0.0000 |\n",
      "| 49.0000 | poutcome=2     |       0.0769 |  nan      |          nan      |          nan      |  nan      |  nan      |  nan      |  nan      |\n",
      "|  0.0000 | age            |       0.0913 |    5.2855 |            0.0041 |            0.0023 |    0.0072 |    0.0056 |    0.0000 |    0.0000 |\n",
      "|  3.0000 | duration       |       0.3088 |  131.3983 |           -0.0324 |            0.0436 |    0.0333 |    0.0472 |    0.0102 |    0.0293 |\n",
      "+---------+----------------+--------------+-----------+-------------------+-------------------+-----------+-----------+-----------+-----------+\n",
      "\n",
      "\n",
      "*******\n",
      "Legend:\n",
      "Importance = Feature Importance\n",
      "     Explanation: A weighted measure of how much of the variance the model is able to explain is due to this column\n",
      "FR_delta = Feature Response Delta Amount\n",
      "     Explanation: Amount this column was incremented or decremented by to calculate the feature reponses\n",
      "FR_Decrementing = Feature Response From Decrementing Values In This Column By One FR_delta\n",
      "     Explanation: Represents how much the predicted output values respond to subtracting one FR_delta amount from every value in this column\n",
      "FR_Incrementing = Feature Response From Incrementing Values In This Column By One FR_delta\n",
      "     Explanation: Represents how much the predicted output values respond to adding one FR_delta amount to every value in this column\n",
      "FRD_MAD = Feature Response From Decrementing- Median Absolute Delta\n",
      "     Explanation: Takes the absolute value of all changes in predictions, then takes the median of those. Useful for seeing if decrementing this feature provokes strong changes that are both positive and negative\n",
      "FRI_MAD = Feature Response From Incrementing- Median Absolute Delta\n",
      "     Explanation: Takes the absolute value of all changes in predictions, then takes the median of those. Useful for seeing if incrementing this feature provokes strong changes that are both positive and negative\n",
      "FRD_abs = Feature Response From Decrementing Avg Absolute Change\n",
      "     Explanation: What is the average absolute change in predicted output values to subtracting one FR_delta amount to every value in this column. Useful for seeing if output is sensitive to a feature, but not in a uniformly positive or negative way\n",
      "FRI_abs = Feature Response From Incrementing Avg Absolute Change\n",
      "     Explanation: What is the average absolute change in predicted output values to adding one FR_delta amount to every value in this column. Useful for seeing if output is sensitive to a feature, but not in a uniformly positive or negative way\n",
      "*******\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<auto_ml.predictor.Predictor at 0x10ec8d898>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ml_predictor.train(train, ml_for_analytics=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is our brier-score-loss, which is the default value we optimized for while training, and is the value returned from .score() unless you requested a custom scoring metric\n",
      "It is a measure of how close the PROBABILITY predictions are.\n",
      "0.0576\n",
      "\n",
      "Here is the trained estimator's overall accuracy (when it predicts a label, how frequently is that the correct label?)\n",
      "92.5%\n",
      "\n",
      "Here is a confusion matrix showing predictions vs. actuals by label:\n",
      "Predicted >     0    1   All\n",
      "v Actual v                  \n",
      "0            2370   32  2402\n",
      "1             172  138   310\n",
      "All          2542  170  2712\n",
      "\n",
      "Here is predictive value by class:\n",
      "Class:  0 = 0.932336742722266\n",
      "Class:  1 = 0.8117647058823529\n",
      "+--------------------------------+-----------------------------------+--------------------------------+\n",
      "| Bucket Edges                   |   Predicted Probability Of Bucket |   Actual Probability of Bucket |\n",
      "|--------------------------------+-----------------------------------+--------------------------------|\n",
      "| (0.015199999999999998, 0.0228] |                            0.0195 |                         0.0000 |\n",
      "| (0.0228, 0.0248]               |                            0.0241 |                         0.0031 |\n",
      "| (0.0248, 0.0273]               |                            0.0261 |                         0.0000 |\n",
      "| (0.0273, 0.0322]               |                            0.0314 |                         0.0088 |\n",
      "| (0.0322, 0.0343]               |                            0.0339 |                         0.0047 |\n",
      "| (0.0343, 0.0541]               |                            0.0423 |                         0.0189 |\n",
      "| (0.0541, 0.0666]               |                            0.0602 |                         0.0449 |\n",
      "| (0.0666, 0.144]                |                            0.0982 |                         0.1148 |\n",
      "| (0.144, 0.334]                 |                            0.2180 |                         0.2731 |\n",
      "| (0.334, 0.97]                  |                            0.5589 |                         0.6728 |\n",
      "+--------------------------------+-----------------------------------+--------------------------------+\n",
      "\n",
      "Here is the accuracy of our trained estimator at each level of predicted probabilities\n",
      "For a verbose description of what this means, please visit the docs:\n",
      "http://auto-ml.readthedocs.io/en/latest/analytics.html#interpreting-predicted-probability-buckets-for-classifiers\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-0.05755529819521337"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ml_predictor.score(features_train,label_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is our brier-score-loss, which is the default value we optimized for while training, and is the value returned from .score() unless you requested a custom scoring metric\n",
      "It is a measure of how close the PROBABILITY predictions are.\n",
      "0.0754\n",
      "\n",
      "Here is the trained estimator's overall accuracy (when it predicts a label, how frequently is that the correct label?)\n",
      "89.5%\n",
      "\n",
      "Here is a confusion matrix showing predictions vs. actuals by label:\n",
      "Predicted >     0    1   All\n",
      "v Actual v                  \n",
      "0            1557   41  1598\n",
      "1             149   62   211\n",
      "All          1706  103  1809\n",
      "\n",
      "Here is predictive value by class:\n",
      "Class:  0 = 0.9126611957796014\n",
      "Class:  1 = 0.6019417475728155\n",
      "+--------------------------------+-----------------------------------+--------------------------------+\n",
      "| Bucket Edges                   |   Predicted Probability Of Bucket |   Actual Probability of Bucket |\n",
      "|--------------------------------+-----------------------------------+--------------------------------|\n",
      "| (0.015199999999999998, 0.0228] |                            0.0195 |                         0.0126 |\n",
      "| (0.0228, 0.0248]               |                            0.0241 |                         0.0000 |\n",
      "| (0.0248, 0.0273]               |                            0.0260 |                         0.0093 |\n",
      "| (0.0273, 0.0322]               |                            0.0314 |                         0.0207 |\n",
      "| (0.0322, 0.0349]               |                            0.0341 |                         0.0166 |\n",
      "| (0.0349, 0.0561]               |                            0.0434 |                         0.0599 |\n",
      "| (0.0561, 0.0666]               |                            0.0596 |                         0.0492 |\n",
      "| (0.0666, 0.119]                |                            0.0944 |                         0.1620 |\n",
      "| (0.119, 0.317]                 |                            0.2024 |                         0.2873 |\n",
      "| (0.317, 0.963]                 |                            0.5394 |                         0.5525 |\n",
      "+--------------------------------+-----------------------------------+--------------------------------+\n",
      "\n",
      "Here is the accuracy of our trained estimator at each level of predicted probabilities\n",
      "For a verbose description of what this means, please visit the docs:\n",
      "http://auto-ml.readthedocs.io/en/latest/analytics.html#interpreting-predicted-probability-buckets-for-classifiers\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-0.07544554098010467"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ml_predictor.score(features_test,label_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "We have saved the trained pipeline to a filed called \"auto_ml_saved_pipeline.dill\"\n",
      "It is saved in the directory: \n",
      "/Users/mbagav200/Desktop/Medium\n",
      "To use it to get predictions, please follow the following flow (adjusting for your own uses as necessary:\n",
      "\n",
      "\n",
      "`from auto_ml.utils_models import load_ml_model\n",
      "`trained_ml_pipeline = load_ml_model(\"auto_ml_saved_pipeline.dill\")\n",
      "`trained_ml_pipeline.predict(data)`\n",
      "\n",
      "\n",
      "Note that this pickle/dill file can only be loaded in an environment with the same modules installed, and running the same Python version.\n",
      "This version of Python is:\n",
      "sys.version_info(major=3, minor=5, micro=2, releaselevel='final', serial=0)\n",
      "\n",
      "\n",
      "When passing in new data to get predictions on, columns that were not present (or were not found to be useful) in the training data will be silently ignored.\n",
      "It is worthwhile to make sure that you feed in all the most useful data points though, to make sure you can get the highest quality predictions.\n"
     ]
    }
   ],
   "source": [
    "file_name = ml_predictor.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from auto_ml.utils_models import load_ml_model\n",
    "\n",
    "trained_model = load_ml_model('auto_ml_saved_pipeline.dill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = trained_model.predict(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.0627740411585786"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trained_model.score(features_train,label_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
